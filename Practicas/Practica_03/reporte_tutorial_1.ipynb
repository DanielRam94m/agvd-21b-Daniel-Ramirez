{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reporte_tutorial_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOQ6WbC-6ZmC"
      },
      "source": [
        "## Práctica 03 &emsp;(23 de Septiembre)\n",
        "## &emsp;Parte 01\n",
        "## &emsp;Daniel Ricardo Ramírez Umaña, B45675"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBvAV8m08EO0"
      },
      "source": [
        "## Parte 01 <br>Cómo elegir un método de selección de características para el aprendizaje automático"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fs8T7i4-LMS"
      },
      "source": [
        "### &emsp;1. Lo aprendido:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEc5HhPRVSVz"
      },
      "source": [
        "#### &emsp;&emsp;1. Métodos de selección de características\n",
        "\n",
        "Con estos métodos se pretende reducir la cantidad de features (características o variables) con el fin de mantener aquellas que son de mayor utilidad para que el modelo de forma eficiente y precisa pueda predecir el valor en una variable objetivo. Además realizar esto nos permite:\n",
        "* Reducir el tiempo de desarrollo de los modelos\n",
        "* Reducir el tiempo de entrenamiento del modelo\n",
        "* Reducir el requerimiento de uso de memoria del sistema\n",
        "* Mejorar el rendimiento de algunos modelos al deshacerse de variables de entrada que no son relevantes.\n",
        "\n",
        "Para filtrar variables podemos hablar de los siguientes modelos:\n",
        "* **Feature Selection:** Estos seleccionan características o variables del dataset con en objetivo de mejorar su rendimiento, desempeño y eficientes.\n",
        "  * **No supervisado:**<br>  Filtran variables sin tomar en consideración la variable objetivo.<br> Por ejemplo pensemos en varables que son en su mayoría nulos, son casi todos el mismo o casi todos muy distintos o presentan poca o ninguna correlación con las demás variables.\n",
        "  * **Supervisado:**<br> Filtran variables considerando la variable objetivo.<br> Una variable no relevante o poco relevante se removerán del modelo.\n",
        "    * **Wrapper:** Genera muchos subconjuntos de variables y selecciona aquel que tenga el mejor rendimiento.<br> Pueden llegar a ser computacionalmete costosos.\n",
        "      * RFE (Recursive Feature Elimination)\n",
        "    * **Filter:**<br> Estos relacionan la relación entre cada variable de entrada y la variable de salida por medio de técnicas estadísticas.\n",
        "      * Métodos Estadísticos\n",
        "      * Métodos de Importancia de la Variable \n",
        "    * **Intrinsic:** Algoritmos de Aprendizaje Automático que realizan la selección o filtrado de variables de forma automática.\n",
        "      * **Algoritmos de Regresión Penalizada** (como por ejemplo *Lasso*).\n",
        "      * Algunos tipos de árboles de desición como los de **Bosque Aleatório**.\n",
        "* **Dimensionality Reduction:**<br> Mediante la representación de las variables de entrada en un espacio de menos dimesión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asPDmVt1cSac"
      },
      "source": [
        "#### &emsp;&emsp; 2. Estadísticas de los métodos de selección de características de los filtros\n",
        "\n",
        "Las variables de entrada se pueden clasificar como:\n",
        "* **Variables Numéricas:**<br> Por ejemplo variables de valor entero o variables de punto flotante.\n",
        "* **Variables Categóricas:**<br> Por ejemplo valores de tipo booleano, variables ordinales y variables nominales.\n",
        "\n",
        "Para saber qué modelo de predicción utilizar es bueno considerar el tipo de variable de salida. en estos casos:\n",
        "* **Salida Numérica:** Uraremos modelos predictivos de regresión.\n",
        "* **Salida Categórica:** Uraremos modelos predictivos de clasificación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WJrvrkVWqAA"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 2.1. Entrada Numérica, Salida Numérica\n",
        "\n",
        "* Si la correlación es lineal utilizar el coeficiente de correlación de **Pearson**.\n",
        "* Si la correlación es no lineal utilizar  el rango de coeficiente de **Spearman**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfbz9lo2W7Tz"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 2.2. Entada Numérica, Salida Categórica\n",
        "\n",
        "* Si la correlación es lineal, utilizar el modelo de coeficiente de correlación de **ANOVA**\n",
        "* Si la correlación es no lineal, utilizar el coeficiente de rango de **Kendall**. Esta asume que la variable categórica es ordinal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UoxJfofW9YQ"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 2.3. Entrada Categórica, Salida Numérica\n",
        "\n",
        "Al revés del caso anterior:\n",
        "\n",
        "* Si la correlación es lineal, utilizar el coeficiente de rango de **Kendall**. Esta asume que la variable categórica es ordinal.\n",
        "* Si la correlación es no lineal, utilizar el modelo de coeficiente de correlación de **ANOVA**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDHU2fL8W_G1"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 2.4. Entrada Categórica, Salida Categórica\n",
        "\n",
        "Para este tenemos dos alternativas:\n",
        "* Utilizar **Chi-squared test** (tablas de contingencia).\n",
        "* O bien utilizar métode de **Información Mutua**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_VNmu4N--HE"
      },
      "source": [
        "![Input/Output Model](https://machinelearningmastery.com/wp-content/uploads/2019/11/How-to-Choose-Feature-Selection-Methods-For-Machine-Learning.png)*Figura 1. Cómo Escoger el Modelo de Selección de Variables para Machine Learning*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1M48iEuVvNz"
      },
      "source": [
        "#### &emsp;&emsp; 3. Consejos y trucos para la selección de características"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKBaCqMmbwC7"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 3.1. Estadísticas de Corelación\n",
        "\n",
        "Podemos contar con funciones que ya nos brinda la bibioteca de **scikit-learn** para la mayoría de las estadísticas necesarias. \n",
        "* Para Person's Correlation Coefficient: `f_regression()`\n",
        "* Para ANOVA: `f_classif()`\n",
        "* Para Chi-Squared: `chi2()`\n",
        "* Mutual Information: `mutual_info_classif()` y `mutual_info_regression()`\n",
        "\n",
        "Y **SciPy** provee otras funciones como `kendalltau()` y `spearmanr()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB0t5jvzb1fh"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 3.2. Método para Selección\n",
        "\n",
        "También con **scikit-learn** podemos hacer uso de distintos métodos de filtrado de variables cuando se ha calculado las estadísticas para cada variable de entrada. De las más usadas puedo contar con:\n",
        "* Para seleccionar el top k de variables: `SelectBest()`\n",
        "* Para seleccionar variables con el maypr percentil: `SelectPercentile()`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPamUH3TdWEa"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 3.3. Transformación de Variables\n",
        "\n",
        "En algunos casos es necesario transformar algunas variables de un tipo a otro, por ejemplo transformar una variable categórica en ordinal y ver si obtienen resultados interesantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDUNsAjKdmJz"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 3.4. ¿Cuál es el Mejor Método?\n",
        "\n",
        "Para esto no hay receta mágica, por lo que para esto lo mejor es utilizar una exploración sistematizada intentando con distintos modelos en diferentes conjuntos de datos con diferentes variables seleccionadas con respecto a diferentes medidas estadísticas y así descubrir cual trabaja de la mejor manera para el problema específico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1EGUBB_d7d9"
      },
      "source": [
        "#### &emsp;&emsp; 4. Ejemplos Trabajados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlRXMDjueD9F"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 4.1. Selección de Caracteríticas de Regresión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bewp81udJLou",
        "outputId": "353a4a0c-f215-49ab-ac6a-f08de240387e"
      },
      "source": [
        "# pearson's correlation feature selection for numeric input and numeric output\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "# generate dataset\n",
        "X, y = make_regression(n_samples=100, n_features=100, n_informative=10)\n",
        "# define feature selection\n",
        "fs = SelectKBest(score_func=f_regression, k=10)\n",
        "# apply feature selection\n",
        "X_selected = fs.fit_transform(X, y)\n",
        "print(X_selected.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utBDD8yDeWlz"
      },
      "source": [
        "#### &emsp;&emsp;&emsp; 4.2. Selección de Caracteríticas de Clasificación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLYB7Jfq6TN8",
        "outputId": "a1a0f3ae-7795-4f34-f2e3-1981be9cb006"
      },
      "source": [
        "# ANOVA feature selection for numeric input and categorical output\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "# generate dataset\n",
        "X, y = make_classification(n_samples=100, n_features=20, n_informative=2)\n",
        "# define feature selection\n",
        "fs = SelectKBest(score_func=f_classif, k=2)\n",
        "# apply feature selection\n",
        "X_selected = fs.fit_transform(X, y)\n",
        "print(X_selected.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poLdVXQBFMm_"
      },
      "source": [
        "### &emsp; 2. Posible uso que le dará a esta materia como profesional.\n",
        "\n",
        "* En mi futuro como profesional en Ciencias de la Computación, es de gran necesidad de conocer modelos para medir el coeficiente de correlación entre mis variables y de esta manera poder tomar decisiones en las mejores convinacioenes de variables para el filtrado de variables antes del entrenamiento de mis modelos y además tener el conocimiento técnico para poder argumentar las decisiones tomadas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T71txAPSJwQD"
      },
      "source": [
        "### &emsp; 3. Aspectos que no le quedan claros, o que quisiera conocer mejor.\n",
        "\n",
        "* En cuanto a los casos en que tenemos inputs categóricos y outputs categóricos, no me queda claso exactamente en qué consiste el método de **Mutual Information** ya que no sé si esto es solo una comparación directa uno a uno de si siempre que una variable tiene una categoría, un valor en otra variable es siempre o casi siempre el mismo.\n",
        "* Me gustaría poder usar ejemplos de cada tipo de filtro de variables para con respecto a la naturaleza del dataset entender mejor el porqué de la selección del modelo.\n",
        "* En los códigos de ejemplo no me queda claro la necesidad de mostrar el shape ya que esto es algo que se estableció en el código, talvez suría útil que se mostrara cuales fueron los seleccionados."
      ]
    }
  ]
}
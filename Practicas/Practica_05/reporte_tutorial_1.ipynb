{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reporte_tutorial_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCRgXZYsAkTb"
      },
      "source": [
        "## **Modelos de Redes Neuronales para Clasificación y Regresión Combinadas**\n",
        "## CI-0163   Análisis de Grandes Volúmenes de Datos\n",
        "## Daniel Ricardo Ramírez Umaña, B45675\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I0G8zlSBHHC"
      },
      "source": [
        "Algunos modelos requieren para sus predicciones que estas puedan ser variables numéricas o categóricas. Para esto podemos usar un enfoque basado en desarrolar modelos predictivos y de clasificación sobre los mismos datos y usar modelos de forma secuencial, o bien se puede usar un enfoque llamado **multi-output model** que se basa en desarrollar un único modelo de red neuronal que pueda predecir tanto un valor numérico como una etiqueta de clase a partir de la misma entrada. Este es relativamente fácil de desarrolar y de evaluar utilizano bibliotecas modernas de aprendizaje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvMuHDWTDgA9"
      },
      "source": [
        "### **Modelo Único de Regresión y Clasificación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsRJZYGEEG1"
      },
      "source": [
        "Para esto podemos hacer uso de dos enfoques, uno de estos es realizar la regresión y la clasificación por aparte y de forma secuencial, o bien usar un modelo que combine ambos tipos de clasificación a la vez."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQLy7B-NE4j5"
      },
      "source": [
        "#### **Separar los Modelos de Regresión y de Clasificación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QO9Dm4gJE5D"
      },
      "source": [
        "Se importan las librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsctwux6JJvF"
      },
      "source": [
        "# regression mlp model for the abalone dataset\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaGA6exaFrXv"
      },
      "source": [
        "Descargamos y observamos un resumen de la información del dataset de Abalone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIj7NwgCFQW3",
        "outputId": "46b11be1-86c6-449c-acae-9e28de72b0fa"
      },
      "source": [
        "# load and summarize the abalone dataset\n",
        "from matplotlib import pyplot\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
        "dataframe = read_csv(url, header=None)\n",
        "# summarize shape\n",
        "print(dataframe.shape)\n",
        "# summarize first few lines\n",
        "print(dataframe.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4177, 9)\n",
            "   0      1      2      3       4       5       6      7   8\n",
            "0  M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.150  15\n",
            "1  M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.070   7\n",
            "2  F  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.210   9\n",
            "3  M  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.155  10\n",
            "4  I  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.055   7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2ioF_5LGb1i"
      },
      "source": [
        "##### **Modelo de Regresión**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRs00AQRHHls"
      },
      "source": [
        "Separamos las columnas en elementos de entrada y de salida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ogUPFNHCWH"
      },
      "source": [
        "# split into input (X) and output (y) variables\n",
        "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
        "X, y = X.astype('float'), y.astype('float')\n",
        "n_features = X.shape[1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYkNtfVOJkuQ"
      },
      "source": [
        "Dividimos el dataset entre 67% de entrenamiento y 33% de testeo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkZKolD-JuYZ"
      },
      "source": [
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fVPcxpgJ5jO"
      },
      "source": [
        "Definimos el modelo de Red Neuronal\\\n",
        "El modelo tendrá dos capas ocultas, la primera con 20 nodos y la segunda con 10 nodos, ambas utilizando activación ReLU e inicialización de pesos \"he normal\" (una buena práctica). El número de capas y nodos se ha elegido de forma arbitraria.\\\n",
        "La capa de salida tendrá un único nodo para predecir un valor numérico y una función de activación lineal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qP3-fEyJ9_t"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='linear'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lma0tZOK95t"
      },
      "source": [
        "Ahora entrenamos el modelo para minimizar el error medio cuadrado (MSE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5LKTHiNLH7y"
      },
      "source": [
        "# compile the keras model\n",
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YodDb1b-Lhb0"
      },
      "source": [
        "Ahora se entrena el modelo por 150 épocas con 32 muestras de minilotes escogidas aleatoriamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIS0xCNtLzFd",
        "outputId": "f05d2d31-00ab-42eb-cb01-adcd788089e2"
      },
      "source": [
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "88/88 - 0s - loss: 55.4883\n",
            "Epoch 2/150\n",
            "88/88 - 0s - loss: 15.8084\n",
            "Epoch 3/150\n",
            "88/88 - 0s - loss: 9.9737\n",
            "Epoch 4/150\n",
            "88/88 - 0s - loss: 9.1230\n",
            "Epoch 5/150\n",
            "88/88 - 0s - loss: 8.3607\n",
            "Epoch 6/150\n",
            "88/88 - 0s - loss: 7.7211\n",
            "Epoch 7/150\n",
            "88/88 - 0s - loss: 7.2214\n",
            "Epoch 8/150\n",
            "88/88 - 0s - loss: 6.8821\n",
            "Epoch 9/150\n",
            "88/88 - 0s - loss: 6.6411\n",
            "Epoch 10/150\n",
            "88/88 - 0s - loss: 6.4969\n",
            "Epoch 11/150\n",
            "88/88 - 0s - loss: 6.3881\n",
            "Epoch 12/150\n",
            "88/88 - 0s - loss: 6.3041\n",
            "Epoch 13/150\n",
            "88/88 - 0s - loss: 6.2595\n",
            "Epoch 14/150\n",
            "88/88 - 0s - loss: 6.1845\n",
            "Epoch 15/150\n",
            "88/88 - 0s - loss: 6.1192\n",
            "Epoch 16/150\n",
            "88/88 - 0s - loss: 6.0665\n",
            "Epoch 17/150\n",
            "88/88 - 0s - loss: 6.0096\n",
            "Epoch 18/150\n",
            "88/88 - 0s - loss: 5.9453\n",
            "Epoch 19/150\n",
            "88/88 - 0s - loss: 5.9029\n",
            "Epoch 20/150\n",
            "88/88 - 0s - loss: 5.8394\n",
            "Epoch 21/150\n",
            "88/88 - 0s - loss: 5.7832\n",
            "Epoch 22/150\n",
            "88/88 - 0s - loss: 5.7369\n",
            "Epoch 23/150\n",
            "88/88 - 0s - loss: 5.7198\n",
            "Epoch 24/150\n",
            "88/88 - 0s - loss: 5.6401\n",
            "Epoch 25/150\n",
            "88/88 - 0s - loss: 5.6144\n",
            "Epoch 26/150\n",
            "88/88 - 0s - loss: 5.5576\n",
            "Epoch 27/150\n",
            "88/88 - 0s - loss: 5.5296\n",
            "Epoch 28/150\n",
            "88/88 - 0s - loss: 5.4640\n",
            "Epoch 29/150\n",
            "88/88 - 0s - loss: 5.4766\n",
            "Epoch 30/150\n",
            "88/88 - 0s - loss: 5.3991\n",
            "Epoch 31/150\n",
            "88/88 - 0s - loss: 5.3657\n",
            "Epoch 32/150\n",
            "88/88 - 0s - loss: 5.3096\n",
            "Epoch 33/150\n",
            "88/88 - 0s - loss: 5.2656\n",
            "Epoch 34/150\n",
            "88/88 - 0s - loss: 5.2449\n",
            "Epoch 35/150\n",
            "88/88 - 0s - loss: 5.2047\n",
            "Epoch 36/150\n",
            "88/88 - 0s - loss: 5.1764\n",
            "Epoch 37/150\n",
            "88/88 - 0s - loss: 5.1385\n",
            "Epoch 38/150\n",
            "88/88 - 0s - loss: 5.1102\n",
            "Epoch 39/150\n",
            "88/88 - 0s - loss: 5.0777\n",
            "Epoch 40/150\n",
            "88/88 - 0s - loss: 5.0562\n",
            "Epoch 41/150\n",
            "88/88 - 0s - loss: 5.0258\n",
            "Epoch 42/150\n",
            "88/88 - 0s - loss: 5.0208\n",
            "Epoch 43/150\n",
            "88/88 - 0s - loss: 4.9735\n",
            "Epoch 44/150\n",
            "88/88 - 0s - loss: 4.9658\n",
            "Epoch 45/150\n",
            "88/88 - 0s - loss: 4.9366\n",
            "Epoch 46/150\n",
            "88/88 - 0s - loss: 4.9311\n",
            "Epoch 47/150\n",
            "88/88 - 0s - loss: 4.9583\n",
            "Epoch 48/150\n",
            "88/88 - 0s - loss: 4.9212\n",
            "Epoch 49/150\n",
            "88/88 - 0s - loss: 4.9355\n",
            "Epoch 50/150\n",
            "88/88 - 0s - loss: 4.8951\n",
            "Epoch 51/150\n",
            "88/88 - 0s - loss: 4.8604\n",
            "Epoch 52/150\n",
            "88/88 - 0s - loss: 4.8547\n",
            "Epoch 53/150\n",
            "88/88 - 0s - loss: 4.8538\n",
            "Epoch 54/150\n",
            "88/88 - 0s - loss: 4.8668\n",
            "Epoch 55/150\n",
            "88/88 - 0s - loss: 4.8598\n",
            "Epoch 56/150\n",
            "88/88 - 0s - loss: 4.8400\n",
            "Epoch 57/150\n",
            "88/88 - 0s - loss: 4.8288\n",
            "Epoch 58/150\n",
            "88/88 - 0s - loss: 4.8345\n",
            "Epoch 59/150\n",
            "88/88 - 0s - loss: 4.8259\n",
            "Epoch 60/150\n",
            "88/88 - 0s - loss: 4.8544\n",
            "Epoch 61/150\n",
            "88/88 - 0s - loss: 4.7995\n",
            "Epoch 62/150\n",
            "88/88 - 0s - loss: 4.7952\n",
            "Epoch 63/150\n",
            "88/88 - 0s - loss: 4.7889\n",
            "Epoch 64/150\n",
            "88/88 - 0s - loss: 4.8202\n",
            "Epoch 65/150\n",
            "88/88 - 0s - loss: 4.7892\n",
            "Epoch 66/150\n",
            "88/88 - 0s - loss: 4.7925\n",
            "Epoch 67/150\n",
            "88/88 - 0s - loss: 4.8191\n",
            "Epoch 68/150\n",
            "88/88 - 0s - loss: 4.7866\n",
            "Epoch 69/150\n",
            "88/88 - 0s - loss: 4.7815\n",
            "Epoch 70/150\n",
            "88/88 - 0s - loss: 4.7551\n",
            "Epoch 71/150\n",
            "88/88 - 0s - loss: 4.7583\n",
            "Epoch 72/150\n",
            "88/88 - 0s - loss: 4.7506\n",
            "Epoch 73/150\n",
            "88/88 - 0s - loss: 4.7514\n",
            "Epoch 74/150\n",
            "88/88 - 0s - loss: 4.7578\n",
            "Epoch 75/150\n",
            "88/88 - 0s - loss: 4.7521\n",
            "Epoch 76/150\n",
            "88/88 - 0s - loss: 4.7459\n",
            "Epoch 77/150\n",
            "88/88 - 0s - loss: 4.7296\n",
            "Epoch 78/150\n",
            "88/88 - 0s - loss: 4.7413\n",
            "Epoch 79/150\n",
            "88/88 - 0s - loss: 4.7302\n",
            "Epoch 80/150\n",
            "88/88 - 0s - loss: 4.7169\n",
            "Epoch 81/150\n",
            "88/88 - 0s - loss: 4.7089\n",
            "Epoch 82/150\n",
            "88/88 - 0s - loss: 4.7346\n",
            "Epoch 83/150\n",
            "88/88 - 0s - loss: 4.6926\n",
            "Epoch 84/150\n",
            "88/88 - 0s - loss: 4.7076\n",
            "Epoch 85/150\n",
            "88/88 - 0s - loss: 4.6886\n",
            "Epoch 86/150\n",
            "88/88 - 0s - loss: 4.7172\n",
            "Epoch 87/150\n",
            "88/88 - 0s - loss: 4.6895\n",
            "Epoch 88/150\n",
            "88/88 - 0s - loss: 4.6820\n",
            "Epoch 89/150\n",
            "88/88 - 0s - loss: 4.6783\n",
            "Epoch 90/150\n",
            "88/88 - 0s - loss: 4.7332\n",
            "Epoch 91/150\n",
            "88/88 - 0s - loss: 4.6696\n",
            "Epoch 92/150\n",
            "88/88 - 0s - loss: 4.6826\n",
            "Epoch 93/150\n",
            "88/88 - 0s - loss: 4.6838\n",
            "Epoch 94/150\n",
            "88/88 - 0s - loss: 4.6661\n",
            "Epoch 95/150\n",
            "88/88 - 0s - loss: 4.6674\n",
            "Epoch 96/150\n",
            "88/88 - 0s - loss: 4.6504\n",
            "Epoch 97/150\n",
            "88/88 - 0s - loss: 4.6582\n",
            "Epoch 98/150\n",
            "88/88 - 0s - loss: 4.6665\n",
            "Epoch 99/150\n",
            "88/88 - 0s - loss: 4.6454\n",
            "Epoch 100/150\n",
            "88/88 - 0s - loss: 4.6394\n",
            "Epoch 101/150\n",
            "88/88 - 0s - loss: 4.6512\n",
            "Epoch 102/150\n",
            "88/88 - 0s - loss: 4.6495\n",
            "Epoch 103/150\n",
            "88/88 - 0s - loss: 4.6394\n",
            "Epoch 104/150\n",
            "88/88 - 0s - loss: 4.6582\n",
            "Epoch 105/150\n",
            "88/88 - 0s - loss: 4.6353\n",
            "Epoch 106/150\n",
            "88/88 - 0s - loss: 4.6365\n",
            "Epoch 107/150\n",
            "88/88 - 0s - loss: 4.6468\n",
            "Epoch 108/150\n",
            "88/88 - 0s - loss: 4.6129\n",
            "Epoch 109/150\n",
            "88/88 - 0s - loss: 4.6474\n",
            "Epoch 110/150\n",
            "88/88 - 0s - loss: 4.6286\n",
            "Epoch 111/150\n",
            "88/88 - 0s - loss: 4.6427\n",
            "Epoch 112/150\n",
            "88/88 - 0s - loss: 4.6036\n",
            "Epoch 113/150\n",
            "88/88 - 0s - loss: 4.6235\n",
            "Epoch 114/150\n",
            "88/88 - 0s - loss: 4.6294\n",
            "Epoch 115/150\n",
            "88/88 - 0s - loss: 4.6247\n",
            "Epoch 116/150\n",
            "88/88 - 0s - loss: 4.6060\n",
            "Epoch 117/150\n",
            "88/88 - 0s - loss: 4.6467\n",
            "Epoch 118/150\n",
            "88/88 - 0s - loss: 4.6228\n",
            "Epoch 119/150\n",
            "88/88 - 0s - loss: 4.6182\n",
            "Epoch 120/150\n",
            "88/88 - 0s - loss: 4.5899\n",
            "Epoch 121/150\n",
            "88/88 - 0s - loss: 4.5962\n",
            "Epoch 122/150\n",
            "88/88 - 0s - loss: 4.5997\n",
            "Epoch 123/150\n",
            "88/88 - 0s - loss: 4.5900\n",
            "Epoch 124/150\n",
            "88/88 - 0s - loss: 4.5859\n",
            "Epoch 125/150\n",
            "88/88 - 0s - loss: 4.5802\n",
            "Epoch 126/150\n",
            "88/88 - 0s - loss: 4.6261\n",
            "Epoch 127/150\n",
            "88/88 - 0s - loss: 4.5816\n",
            "Epoch 128/150\n",
            "88/88 - 0s - loss: 4.5886\n",
            "Epoch 129/150\n",
            "88/88 - 0s - loss: 4.5778\n",
            "Epoch 130/150\n",
            "88/88 - 0s - loss: 4.6046\n",
            "Epoch 131/150\n",
            "88/88 - 0s - loss: 4.6047\n",
            "Epoch 132/150\n",
            "88/88 - 0s - loss: 4.6057\n",
            "Epoch 133/150\n",
            "88/88 - 0s - loss: 4.5655\n",
            "Epoch 134/150\n",
            "88/88 - 0s - loss: 4.5512\n",
            "Epoch 135/150\n",
            "88/88 - 0s - loss: 4.5726\n",
            "Epoch 136/150\n",
            "88/88 - 0s - loss: 4.5550\n",
            "Epoch 137/150\n",
            "88/88 - 0s - loss: 4.5973\n",
            "Epoch 138/150\n",
            "88/88 - 0s - loss: 4.5494\n",
            "Epoch 139/150\n",
            "88/88 - 0s - loss: 4.5557\n",
            "Epoch 140/150\n",
            "88/88 - 0s - loss: 4.5605\n",
            "Epoch 141/150\n",
            "88/88 - 0s - loss: 4.5896\n",
            "Epoch 142/150\n",
            "88/88 - 0s - loss: 4.5543\n",
            "Epoch 143/150\n",
            "88/88 - 0s - loss: 4.5605\n",
            "Epoch 144/150\n",
            "88/88 - 0s - loss: 4.5393\n",
            "Epoch 145/150\n",
            "88/88 - 0s - loss: 4.5866\n",
            "Epoch 146/150\n",
            "88/88 - 0s - loss: 4.5810\n",
            "Epoch 147/150\n",
            "88/88 - 0s - loss: 4.5839\n",
            "Epoch 148/150\n",
            "88/88 - 0s - loss: 4.5559\n",
            "Epoch 149/150\n",
            "88/88 - 0s - loss: 4.5668\n",
            "Epoch 150/150\n",
            "88/88 - 0s - loss: 4.5342\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5086bd090>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NotzeHQMMxYO"
      },
      "source": [
        "Finalmente evaluaremos el modelo y reporteremos le MSE Absoluto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nzRmvhNM4k5",
        "outputId": "4df37e5e-dffc-4ce5-b0d4-773ad468b284"
      },
      "source": [
        "# evaluate on test set\n",
        "yhat = model.predict(X_test)\n",
        "error = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % error)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 1.493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VceUSvPsNGeh"
      },
      "source": [
        "##### **Modelo de Clasificación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl2EtTMyQMQ3"
      },
      "source": [
        "Las dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY3u_JntQOdI"
      },
      "source": [
        "# classification mlp model for the abalone dataset\n",
        "from numpy import unique\n",
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPd-PN4xPPtP"
      },
      "source": [
        "Para ello es necesario asignar primero un número entero distinto para cada valor del \"anillo\", empezando por 0 y terminando por el número total de \"clases\" menos uno.\n",
        "\n",
        "Esto se puede conseguir utilizando el LabelEncoder.\n",
        "\n",
        "También podemos registrar el número total de clases como el número total de valores de clase únicos codificados, que serán necesarios para el modelo más adelante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HBNb6IINLca"
      },
      "source": [
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "n_class = len(unique(y))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lqO_y12QaNG"
      },
      "source": [
        "Definimos el modelo y cambiamos el número de salidas para que iguale el número de clases y usar la función de activación softmax que es común para la clasificación multiclase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS0reJlSQyP2"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(n_class, activation='softmax'))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70Vs44ymQ5Nd"
      },
      "source": [
        "Se minimiza la función de pérdida de entropía cruzada categórica dispersa, apropiada para tareas de clasificación multiclase con etiquetas de clase codificadas en números enteros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTvHOeRhQ6lu"
      },
      "source": [
        "# compile the keras model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNtb2SjcRtZY"
      },
      "source": [
        "Evaluamos el modelo con accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZcsKOh4RkWR",
        "outputId": "a7ee1a2b-087c-4acf-9794-a3a8e16927b5"
      },
      "source": [
        "# evaluate on test set\n",
        "yhat = model.predict(X_test)\n",
        "yhat = argmax(yhat, axis=-1).astype('int')\n",
        "acc = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.3f' % acc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKsaNpRmFLVB"
      },
      "source": [
        "#### **Combinar los Modelos de Regresión y de Clasificación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPhrsui6R8Ht"
      },
      "source": [
        "Las dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Id7yEU6R_O8"
      },
      "source": [
        "# mlp for combined regression and classification predictions on the abalone dataset\n",
        "from numpy import unique\n",
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRj2qMKFSEeE"
      },
      "source": [
        "Cargamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJbq0BtXAbhW"
      },
      "source": [
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
        "dataframe = read_csv(url, header=None)\n",
        "dataset = dataframe.values"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-BSofaBSK7f"
      },
      "source": [
        "Dividimos el dataset en elementos de entrada y de salida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4uT7lK3SRDc"
      },
      "source": [
        "# split into input (X) and output (y) variables\n",
        "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
        "X, y = X.astype('float'), y.astype('float')\n",
        "n_features = X.shape[1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAjIqqtFSWG4"
      },
      "source": [
        "Cambiamos las variables categóricas a numéricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t9nL75jSVqA"
      },
      "source": [
        "# encode strings to integer\n",
        "y_class = LabelEncoder().fit_transform(y)\n",
        "n_class = len(unique(y_class))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCQr0DOFSoBY"
      },
      "source": [
        "Dividimos el dataset entre el que será de entrenamiento y el que será de testeo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy7cPpK0Syri"
      },
      "source": [
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test, y_train_class, y_test_class = train_test_split(X, y, y_class, test_size=0.33, random_state=1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLlmWc0S6Ye"
      },
      "source": [
        "Definimos el modelo a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grJlVOccS-l5"
      },
      "source": [
        "# input\n",
        "visible = Input(shape=(n_features,))\n",
        "hidden1 = Dense(20, activation='relu', kernel_initializer='he_normal')(visible)\n",
        "hidden2 = Dense(10, activation='relu', kernel_initializer='he_normal')(hidden1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26lhHXGfTWCz"
      },
      "source": [
        "Capa de salida de regresión que tiene un solo nodo y una función de activación lineal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2W3g8B8TZKz"
      },
      "source": [
        "# regression output\n",
        "out_reg = Dense(1, activation='linear')(hidden2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyCYCyk2TjRv"
      },
      "source": [
        "capa de salida de clasificación que tiene un nodo para cada clase que se predice y utiliza una función de activación softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC62PLCJTka7"
      },
      "source": [
        "# classification output\n",
        "out_clas = Dense(n_class, activation='softmax')(hidden2)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glEUFo6zTswt"
      },
      "source": [
        "Se define una única capa de entrada y dos capas de salida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jea4fyoaT7_l"
      },
      "source": [
        "# define model\n",
        "model = Model(inputs=visible, outputs=[out_reg, out_clas])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PykmHiJHUAc5"
      },
      "source": [
        "# compile the keras model\n",
        "model.compile(loss=['mse','sparse_categorical_crossentropy'], optimizer='adam')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YME2sR7IUKpd"
      },
      "source": [
        "Graficamos el modelo que tenemos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "CU_6R6JQUD3X",
        "outputId": "0cf9e586-a813-44ac-acc8-434b9b51774b"
      },
      "source": [
        "# plot graph of model\n",
        "plot_model(model, to_file='model.png', show_shapes=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyyCUikBUSG0"
      },
      "source": [
        "Ajustamos el modelo al dataset en untotal de 150 épocas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOpsWPXaUXP-",
        "outputId": "81fa184f-6072-4695-8dc7-19b14d9532fd"
      },
      "source": [
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, [y_train,y_train_class], epochs=150, batch_size=32, verbose=2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "88/88 - 1s - loss: 107.2401 - dense_11_loss: 103.9796 - dense_12_loss: 3.2605\n",
            "Epoch 2/150\n",
            "88/88 - 0s - loss: 79.1596 - dense_11_loss: 76.1710 - dense_12_loss: 2.9886\n",
            "Epoch 3/150\n",
            "88/88 - 0s - loss: 44.5070 - dense_11_loss: 41.7761 - dense_12_loss: 2.7309\n",
            "Epoch 4/150\n",
            "88/88 - 0s - loss: 15.3975 - dense_11_loss: 12.8223 - dense_12_loss: 2.5752\n",
            "Epoch 5/150\n",
            "88/88 - 0s - loss: 10.6050 - dense_11_loss: 8.0857 - dense_12_loss: 2.5194\n",
            "Epoch 6/150\n",
            "88/88 - 0s - loss: 10.3967 - dense_11_loss: 7.8894 - dense_12_loss: 2.5072\n",
            "Epoch 7/150\n",
            "88/88 - 0s - loss: 10.2270 - dense_11_loss: 7.7291 - dense_12_loss: 2.4979\n",
            "Epoch 8/150\n",
            "88/88 - 0s - loss: 10.0379 - dense_11_loss: 7.5494 - dense_12_loss: 2.4885\n",
            "Epoch 9/150\n",
            "88/88 - 0s - loss: 9.7899 - dense_11_loss: 7.3168 - dense_12_loss: 2.4731\n",
            "Epoch 10/150\n",
            "88/88 - 0s - loss: 9.5693 - dense_11_loss: 7.1265 - dense_12_loss: 2.4428\n",
            "Epoch 11/150\n",
            "88/88 - 0s - loss: 9.3636 - dense_11_loss: 6.9723 - dense_12_loss: 2.3913\n",
            "Epoch 12/150\n",
            "88/88 - 0s - loss: 9.1882 - dense_11_loss: 6.8381 - dense_12_loss: 2.3500\n",
            "Epoch 13/150\n",
            "88/88 - 0s - loss: 9.0482 - dense_11_loss: 6.7333 - dense_12_loss: 2.3149\n",
            "Epoch 14/150\n",
            "88/88 - 0s - loss: 8.9158 - dense_11_loss: 6.6254 - dense_12_loss: 2.2904\n",
            "Epoch 15/150\n",
            "88/88 - 0s - loss: 8.7934 - dense_11_loss: 6.5291 - dense_12_loss: 2.2642\n",
            "Epoch 16/150\n",
            "88/88 - 0s - loss: 8.6303 - dense_11_loss: 6.3886 - dense_12_loss: 2.2417\n",
            "Epoch 17/150\n",
            "88/88 - 0s - loss: 8.4524 - dense_11_loss: 6.2214 - dense_12_loss: 2.2310\n",
            "Epoch 18/150\n",
            "88/88 - 0s - loss: 8.2766 - dense_11_loss: 6.0581 - dense_12_loss: 2.2185\n",
            "Epoch 19/150\n",
            "88/88 - 0s - loss: 8.1053 - dense_11_loss: 5.9018 - dense_12_loss: 2.2035\n",
            "Epoch 20/150\n",
            "88/88 - 0s - loss: 7.9247 - dense_11_loss: 5.7291 - dense_12_loss: 2.1956\n",
            "Epoch 21/150\n",
            "88/88 - 0s - loss: 7.7785 - dense_11_loss: 5.5938 - dense_12_loss: 2.1847\n",
            "Epoch 22/150\n",
            "88/88 - 0s - loss: 7.6516 - dense_11_loss: 5.4799 - dense_12_loss: 2.1717\n",
            "Epoch 23/150\n",
            "88/88 - 0s - loss: 7.5259 - dense_11_loss: 5.3618 - dense_12_loss: 2.1640\n",
            "Epoch 24/150\n",
            "88/88 - 0s - loss: 7.4235 - dense_11_loss: 5.2706 - dense_12_loss: 2.1529\n",
            "Epoch 25/150\n",
            "88/88 - 0s - loss: 7.3567 - dense_11_loss: 5.2122 - dense_12_loss: 2.1445\n",
            "Epoch 26/150\n",
            "88/88 - 0s - loss: 7.2925 - dense_11_loss: 5.1601 - dense_12_loss: 2.1324\n",
            "Epoch 27/150\n",
            "88/88 - 0s - loss: 7.2421 - dense_11_loss: 5.1161 - dense_12_loss: 2.1260\n",
            "Epoch 28/150\n",
            "88/88 - 0s - loss: 7.1988 - dense_11_loss: 5.0827 - dense_12_loss: 2.1161\n",
            "Epoch 29/150\n",
            "88/88 - 0s - loss: 7.1423 - dense_11_loss: 5.0328 - dense_12_loss: 2.1095\n",
            "Epoch 30/150\n",
            "88/88 - 0s - loss: 7.1660 - dense_11_loss: 5.0623 - dense_12_loss: 2.1037\n",
            "Epoch 31/150\n",
            "88/88 - 0s - loss: 7.1027 - dense_11_loss: 5.0073 - dense_12_loss: 2.0954\n",
            "Epoch 32/150\n",
            "88/88 - 0s - loss: 7.0555 - dense_11_loss: 4.9661 - dense_12_loss: 2.0895\n",
            "Epoch 33/150\n",
            "88/88 - 0s - loss: 7.0340 - dense_11_loss: 4.9499 - dense_12_loss: 2.0840\n",
            "Epoch 34/150\n",
            "88/88 - 0s - loss: 7.0507 - dense_11_loss: 4.9689 - dense_12_loss: 2.0818\n",
            "Epoch 35/150\n",
            "88/88 - 0s - loss: 6.9676 - dense_11_loss: 4.8916 - dense_12_loss: 2.0760\n",
            "Epoch 36/150\n",
            "88/88 - 0s - loss: 6.9236 - dense_11_loss: 4.8513 - dense_12_loss: 2.0723\n",
            "Epoch 37/150\n",
            "88/88 - 0s - loss: 6.9059 - dense_11_loss: 4.8374 - dense_12_loss: 2.0685\n",
            "Epoch 38/150\n",
            "88/88 - 0s - loss: 6.8813 - dense_11_loss: 4.8177 - dense_12_loss: 2.0636\n",
            "Epoch 39/150\n",
            "88/88 - 0s - loss: 6.8670 - dense_11_loss: 4.8067 - dense_12_loss: 2.0603\n",
            "Epoch 40/150\n",
            "88/88 - 0s - loss: 6.8720 - dense_11_loss: 4.8133 - dense_12_loss: 2.0587\n",
            "Epoch 41/150\n",
            "88/88 - 0s - loss: 6.8399 - dense_11_loss: 4.7860 - dense_12_loss: 2.0539\n",
            "Epoch 42/150\n",
            "88/88 - 0s - loss: 6.8016 - dense_11_loss: 4.7515 - dense_12_loss: 2.0501\n",
            "Epoch 43/150\n",
            "88/88 - 0s - loss: 6.8124 - dense_11_loss: 4.7637 - dense_12_loss: 2.0487\n",
            "Epoch 44/150\n",
            "88/88 - 0s - loss: 6.7973 - dense_11_loss: 4.7531 - dense_12_loss: 2.0442\n",
            "Epoch 45/150\n",
            "88/88 - 0s - loss: 6.7856 - dense_11_loss: 4.7435 - dense_12_loss: 2.0421\n",
            "Epoch 46/150\n",
            "88/88 - 0s - loss: 6.7668 - dense_11_loss: 4.7277 - dense_12_loss: 2.0391\n",
            "Epoch 47/150\n",
            "88/88 - 0s - loss: 6.7575 - dense_11_loss: 4.7198 - dense_12_loss: 2.0377\n",
            "Epoch 48/150\n",
            "88/88 - 0s - loss: 6.7555 - dense_11_loss: 4.7225 - dense_12_loss: 2.0331\n",
            "Epoch 49/150\n",
            "88/88 - 0s - loss: 6.7291 - dense_11_loss: 4.6973 - dense_12_loss: 2.0318\n",
            "Epoch 50/150\n",
            "88/88 - 0s - loss: 6.7315 - dense_11_loss: 4.7008 - dense_12_loss: 2.0307\n",
            "Epoch 51/150\n",
            "88/88 - 0s - loss: 6.7811 - dense_11_loss: 4.7505 - dense_12_loss: 2.0306\n",
            "Epoch 52/150\n",
            "88/88 - 0s - loss: 6.6989 - dense_11_loss: 4.6740 - dense_12_loss: 2.0249\n",
            "Epoch 53/150\n",
            "88/88 - 0s - loss: 6.7086 - dense_11_loss: 4.6852 - dense_12_loss: 2.0234\n",
            "Epoch 54/150\n",
            "88/88 - 0s - loss: 6.7626 - dense_11_loss: 4.7389 - dense_12_loss: 2.0237\n",
            "Epoch 55/150\n",
            "88/88 - 0s - loss: 6.6938 - dense_11_loss: 4.6740 - dense_12_loss: 2.0198\n",
            "Epoch 56/150\n",
            "88/88 - 0s - loss: 6.7062 - dense_11_loss: 4.6862 - dense_12_loss: 2.0200\n",
            "Epoch 57/150\n",
            "88/88 - 0s - loss: 6.7364 - dense_11_loss: 4.7178 - dense_12_loss: 2.0186\n",
            "Epoch 58/150\n",
            "88/88 - 0s - loss: 6.6782 - dense_11_loss: 4.6643 - dense_12_loss: 2.0140\n",
            "Epoch 59/150\n",
            "88/88 - 0s - loss: 6.6754 - dense_11_loss: 4.6625 - dense_12_loss: 2.0128\n",
            "Epoch 60/150\n",
            "88/88 - 0s - loss: 6.6750 - dense_11_loss: 4.6629 - dense_12_loss: 2.0121\n",
            "Epoch 61/150\n",
            "88/88 - 0s - loss: 6.6663 - dense_11_loss: 4.6552 - dense_12_loss: 2.0111\n",
            "Epoch 62/150\n",
            "88/88 - 0s - loss: 6.6725 - dense_11_loss: 4.6623 - dense_12_loss: 2.0102\n",
            "Epoch 63/150\n",
            "88/88 - 0s - loss: 6.6502 - dense_11_loss: 4.6423 - dense_12_loss: 2.0079\n",
            "Epoch 64/150\n",
            "88/88 - 0s - loss: 6.6421 - dense_11_loss: 4.6358 - dense_12_loss: 2.0063\n",
            "Epoch 65/150\n",
            "88/88 - 0s - loss: 6.6515 - dense_11_loss: 4.6458 - dense_12_loss: 2.0056\n",
            "Epoch 66/150\n",
            "88/88 - 0s - loss: 6.6509 - dense_11_loss: 4.6456 - dense_12_loss: 2.0052\n",
            "Epoch 67/150\n",
            "88/88 - 0s - loss: 6.6230 - dense_11_loss: 4.6194 - dense_12_loss: 2.0036\n",
            "Epoch 68/150\n",
            "88/88 - 0s - loss: 6.6382 - dense_11_loss: 4.6346 - dense_12_loss: 2.0035\n",
            "Epoch 69/150\n",
            "88/88 - 0s - loss: 6.6142 - dense_11_loss: 4.6142 - dense_12_loss: 2.0000\n",
            "Epoch 70/150\n",
            "88/88 - 0s - loss: 6.6303 - dense_11_loss: 4.6303 - dense_12_loss: 2.0000\n",
            "Epoch 71/150\n",
            "88/88 - 0s - loss: 6.6282 - dense_11_loss: 4.6289 - dense_12_loss: 1.9993\n",
            "Epoch 72/150\n",
            "88/88 - 0s - loss: 6.6408 - dense_11_loss: 4.6427 - dense_12_loss: 1.9981\n",
            "Epoch 73/150\n",
            "88/88 - 0s - loss: 6.6606 - dense_11_loss: 4.6619 - dense_12_loss: 1.9987\n",
            "Epoch 74/150\n",
            "88/88 - 0s - loss: 6.5934 - dense_11_loss: 4.5972 - dense_12_loss: 1.9962\n",
            "Epoch 75/150\n",
            "88/88 - 0s - loss: 6.5987 - dense_11_loss: 4.6034 - dense_12_loss: 1.9953\n",
            "Epoch 76/150\n",
            "88/88 - 0s - loss: 6.6289 - dense_11_loss: 4.6325 - dense_12_loss: 1.9963\n",
            "Epoch 77/150\n",
            "88/88 - 0s - loss: 6.6025 - dense_11_loss: 4.6092 - dense_12_loss: 1.9933\n",
            "Epoch 78/150\n",
            "88/88 - 0s - loss: 6.5798 - dense_11_loss: 4.5867 - dense_12_loss: 1.9931\n",
            "Epoch 79/150\n",
            "88/88 - 0s - loss: 6.5799 - dense_11_loss: 4.5902 - dense_12_loss: 1.9897\n",
            "Epoch 80/150\n",
            "88/88 - 0s - loss: 6.6141 - dense_11_loss: 4.6220 - dense_12_loss: 1.9921\n",
            "Epoch 81/150\n",
            "88/88 - 0s - loss: 6.5688 - dense_11_loss: 4.5809 - dense_12_loss: 1.9879\n",
            "Epoch 82/150\n",
            "88/88 - 0s - loss: 6.6027 - dense_11_loss: 4.6136 - dense_12_loss: 1.9891\n",
            "Epoch 83/150\n",
            "88/88 - 0s - loss: 6.5782 - dense_11_loss: 4.5918 - dense_12_loss: 1.9864\n",
            "Epoch 84/150\n",
            "88/88 - 0s - loss: 6.5920 - dense_11_loss: 4.6057 - dense_12_loss: 1.9864\n",
            "Epoch 85/150\n",
            "88/88 - 0s - loss: 6.5543 - dense_11_loss: 4.5690 - dense_12_loss: 1.9853\n",
            "Epoch 86/150\n",
            "88/88 - 0s - loss: 6.5980 - dense_11_loss: 4.6124 - dense_12_loss: 1.9856\n",
            "Epoch 87/150\n",
            "88/88 - 0s - loss: 6.5745 - dense_11_loss: 4.5882 - dense_12_loss: 1.9863\n",
            "Epoch 88/150\n",
            "88/88 - 0s - loss: 6.5700 - dense_11_loss: 4.5865 - dense_12_loss: 1.9836\n",
            "Epoch 89/150\n",
            "88/88 - 0s - loss: 6.5476 - dense_11_loss: 4.5661 - dense_12_loss: 1.9814\n",
            "Epoch 90/150\n",
            "88/88 - 0s - loss: 6.5540 - dense_11_loss: 4.5716 - dense_12_loss: 1.9825\n",
            "Epoch 91/150\n",
            "88/88 - 0s - loss: 6.6118 - dense_11_loss: 4.6275 - dense_12_loss: 1.9842\n",
            "Epoch 92/150\n",
            "88/88 - 0s - loss: 6.5302 - dense_11_loss: 4.5513 - dense_12_loss: 1.9789\n",
            "Epoch 93/150\n",
            "88/88 - 0s - loss: 6.5545 - dense_11_loss: 4.5763 - dense_12_loss: 1.9781\n",
            "Epoch 94/150\n",
            "88/88 - 0s - loss: 6.5496 - dense_11_loss: 4.5714 - dense_12_loss: 1.9782\n",
            "Epoch 95/150\n",
            "88/88 - 0s - loss: 6.5944 - dense_11_loss: 4.6155 - dense_12_loss: 1.9789\n",
            "Epoch 96/150\n",
            "88/88 - 0s - loss: 6.5293 - dense_11_loss: 4.5531 - dense_12_loss: 1.9761\n",
            "Epoch 97/150\n",
            "88/88 - 0s - loss: 6.5659 - dense_11_loss: 4.5883 - dense_12_loss: 1.9776\n",
            "Epoch 98/150\n",
            "88/88 - 0s - loss: 6.5720 - dense_11_loss: 4.5931 - dense_12_loss: 1.9789\n",
            "Epoch 99/150\n",
            "88/88 - 0s - loss: 6.5307 - dense_11_loss: 4.5562 - dense_12_loss: 1.9745\n",
            "Epoch 100/150\n",
            "88/88 - 0s - loss: 6.5356 - dense_11_loss: 4.5627 - dense_12_loss: 1.9729\n",
            "Epoch 101/150\n",
            "88/88 - 0s - loss: 6.5659 - dense_11_loss: 4.5916 - dense_12_loss: 1.9743\n",
            "Epoch 102/150\n",
            "88/88 - 0s - loss: 6.5334 - dense_11_loss: 4.5613 - dense_12_loss: 1.9721\n",
            "Epoch 103/150\n",
            "88/88 - 0s - loss: 6.5458 - dense_11_loss: 4.5732 - dense_12_loss: 1.9726\n",
            "Epoch 104/150\n",
            "88/88 - 0s - loss: 6.5342 - dense_11_loss: 4.5628 - dense_12_loss: 1.9714\n",
            "Epoch 105/150\n",
            "88/88 - 0s - loss: 6.5279 - dense_11_loss: 4.5580 - dense_12_loss: 1.9699\n",
            "Epoch 106/150\n",
            "88/88 - 0s - loss: 6.5566 - dense_11_loss: 4.5833 - dense_12_loss: 1.9733\n",
            "Epoch 107/150\n",
            "88/88 - 0s - loss: 6.5530 - dense_11_loss: 4.5827 - dense_12_loss: 1.9703\n",
            "Epoch 108/150\n",
            "88/88 - 0s - loss: 6.5233 - dense_11_loss: 4.5556 - dense_12_loss: 1.9676\n",
            "Epoch 109/150\n",
            "88/88 - 0s - loss: 6.4994 - dense_11_loss: 4.5338 - dense_12_loss: 1.9656\n",
            "Epoch 110/150\n",
            "88/88 - 0s - loss: 6.5144 - dense_11_loss: 4.5463 - dense_12_loss: 1.9681\n",
            "Epoch 111/150\n",
            "88/88 - 0s - loss: 6.5449 - dense_11_loss: 4.5769 - dense_12_loss: 1.9679\n",
            "Epoch 112/150\n",
            "88/88 - 0s - loss: 6.5000 - dense_11_loss: 4.5351 - dense_12_loss: 1.9649\n",
            "Epoch 113/150\n",
            "88/88 - 0s - loss: 6.5228 - dense_11_loss: 4.5560 - dense_12_loss: 1.9668\n",
            "Epoch 114/150\n",
            "88/88 - 0s - loss: 6.5325 - dense_11_loss: 4.5663 - dense_12_loss: 1.9662\n",
            "Epoch 115/150\n",
            "88/88 - 0s - loss: 6.5107 - dense_11_loss: 4.5457 - dense_12_loss: 1.9649\n",
            "Epoch 116/150\n",
            "88/88 - 0s - loss: 6.5003 - dense_11_loss: 4.5359 - dense_12_loss: 1.9644\n",
            "Epoch 117/150\n",
            "88/88 - 0s - loss: 6.4857 - dense_11_loss: 4.5233 - dense_12_loss: 1.9624\n",
            "Epoch 118/150\n",
            "88/88 - 0s - loss: 6.5317 - dense_11_loss: 4.5660 - dense_12_loss: 1.9657\n",
            "Epoch 119/150\n",
            "88/88 - 0s - loss: 6.5256 - dense_11_loss: 4.5604 - dense_12_loss: 1.9652\n",
            "Epoch 120/150\n",
            "88/88 - 0s - loss: 6.4807 - dense_11_loss: 4.5188 - dense_12_loss: 1.9619\n",
            "Epoch 121/150\n",
            "88/88 - 0s - loss: 6.4788 - dense_11_loss: 4.5172 - dense_12_loss: 1.9616\n",
            "Epoch 122/150\n",
            "88/88 - 0s - loss: 6.4773 - dense_11_loss: 4.5168 - dense_12_loss: 1.9605\n",
            "Epoch 123/150\n",
            "88/88 - 0s - loss: 6.4997 - dense_11_loss: 4.5375 - dense_12_loss: 1.9622\n",
            "Epoch 124/150\n",
            "88/88 - 0s - loss: 6.5001 - dense_11_loss: 4.5388 - dense_12_loss: 1.9613\n",
            "Epoch 125/150\n",
            "88/88 - 0s - loss: 6.4737 - dense_11_loss: 4.5137 - dense_12_loss: 1.9600\n",
            "Epoch 126/150\n",
            "88/88 - 0s - loss: 6.5039 - dense_11_loss: 4.5425 - dense_12_loss: 1.9614\n",
            "Epoch 127/150\n",
            "88/88 - 0s - loss: 6.4843 - dense_11_loss: 4.5255 - dense_12_loss: 1.9588\n",
            "Epoch 128/150\n",
            "88/88 - 0s - loss: 6.4644 - dense_11_loss: 4.5073 - dense_12_loss: 1.9571\n",
            "Epoch 129/150\n",
            "88/88 - 0s - loss: 6.4895 - dense_11_loss: 4.5298 - dense_12_loss: 1.9597\n",
            "Epoch 130/150\n",
            "88/88 - 0s - loss: 6.4948 - dense_11_loss: 4.5357 - dense_12_loss: 1.9591\n",
            "Epoch 131/150\n",
            "88/88 - 0s - loss: 6.4844 - dense_11_loss: 4.5261 - dense_12_loss: 1.9583\n",
            "Epoch 132/150\n",
            "88/88 - 0s - loss: 6.4725 - dense_11_loss: 4.5145 - dense_12_loss: 1.9580\n",
            "Epoch 133/150\n",
            "88/88 - 0s - loss: 6.4593 - dense_11_loss: 4.5003 - dense_12_loss: 1.9591\n",
            "Epoch 134/150\n",
            "88/88 - 0s - loss: 6.4861 - dense_11_loss: 4.5279 - dense_12_loss: 1.9582\n",
            "Epoch 135/150\n",
            "88/88 - 0s - loss: 6.4545 - dense_11_loss: 4.4987 - dense_12_loss: 1.9557\n",
            "Epoch 136/150\n",
            "88/88 - 0s - loss: 6.4585 - dense_11_loss: 4.5035 - dense_12_loss: 1.9550\n",
            "Epoch 137/150\n",
            "88/88 - 0s - loss: 6.4621 - dense_11_loss: 4.5076 - dense_12_loss: 1.9546\n",
            "Epoch 138/150\n",
            "88/88 - 0s - loss: 6.4601 - dense_11_loss: 4.5046 - dense_12_loss: 1.9555\n",
            "Epoch 139/150\n",
            "88/88 - 0s - loss: 6.4590 - dense_11_loss: 4.5026 - dense_12_loss: 1.9564\n",
            "Epoch 140/150\n",
            "88/88 - 0s - loss: 6.4628 - dense_11_loss: 4.5067 - dense_12_loss: 1.9561\n",
            "Epoch 141/150\n",
            "88/88 - 0s - loss: 6.4646 - dense_11_loss: 4.5093 - dense_12_loss: 1.9553\n",
            "Epoch 142/150\n",
            "88/88 - 0s - loss: 6.4623 - dense_11_loss: 4.5079 - dense_12_loss: 1.9544\n",
            "Epoch 143/150\n",
            "88/88 - 0s - loss: 6.4669 - dense_11_loss: 4.5110 - dense_12_loss: 1.9559\n",
            "Epoch 144/150\n",
            "88/88 - 0s - loss: 6.4746 - dense_11_loss: 4.5193 - dense_12_loss: 1.9553\n",
            "Epoch 145/150\n",
            "88/88 - 0s - loss: 6.4806 - dense_11_loss: 4.5251 - dense_12_loss: 1.9555\n",
            "Epoch 146/150\n",
            "88/88 - 0s - loss: 6.4732 - dense_11_loss: 4.5179 - dense_12_loss: 1.9552\n",
            "Epoch 147/150\n",
            "88/88 - 0s - loss: 6.4437 - dense_11_loss: 4.4895 - dense_12_loss: 1.9541\n",
            "Epoch 148/150\n",
            "88/88 - 0s - loss: 6.4328 - dense_11_loss: 4.4820 - dense_12_loss: 1.9508\n",
            "Epoch 149/150\n",
            "88/88 - 0s - loss: 6.4514 - dense_11_loss: 4.4983 - dense_12_loss: 1.9531\n",
            "Epoch 150/150\n",
            "88/88 - 0s - loss: 6.4673 - dense_11_loss: 4.5130 - dense_12_loss: 1.9543\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5098a92d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzsq80iCUeXM"
      },
      "source": [
        "Ahora se realizan algunas predicciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psTEBSiJUhsE"
      },
      "source": [
        "# make predictions on test set\n",
        "yhat1, yhat2 = model.predict(X_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63xYA8QzUlSZ"
      },
      "source": [
        "Ahora se calcula el error para el modelo de regresión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68w14icCUucA",
        "outputId": "644d835b-38e0-407c-d2dc-2c453955e63d"
      },
      "source": [
        "# calculate error for regression model\n",
        "error = mean_absolute_error(y_test, yhat1)\n",
        "print('MAE: %.3f' % error)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 1.505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_P0s3-CUw43"
      },
      "source": [
        "Finalmente se evalúa la predicción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibe3XfMnU_2_",
        "outputId": "f0e619e7-21b7-4f3b-bd31-19eb32fa2a6f"
      },
      "source": [
        "# evaluate accuracy for classification model\n",
        "yhat2 = argmax(yhat2, axis=-1).astype('int')\n",
        "acc = accuracy_score(y_test_class, yhat2)\n",
        "print('Accuracy: %.3f' % acc)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ee09bglIe2v"
      },
      "source": [
        "## **Qué no me queda claro**\n",
        "\n",
        "En cuanto al modelo que combina tanto la Regresión como la Clasificación en cunjunto, no me queda claro exactamente como es que este los combina, no sé si es que se ejecutan a la vez o de forma secuencial pero intercalados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXHGYNcyVyOo"
      },
      "source": [
        "## **Breve Reporte**\n",
        "\n",
        "#### **Resumen del tema tratado:** \n",
        "\n",
        "Existen formas para poder evaluar modelos cuyos valores de salida pueden combinar tanto clasificación como regresión, para esto es importante aplicar los conosimientos de las funciones de activación para las capas tanto internas como de salida y luego evaluar estos modelos.\n",
        "\n",
        "#### **Comentarios sobre algo aprendido:**\n",
        "\n",
        "Cuando se requiere tanto variables categóricas como numéricas para aplicar a la vez clasificación y regresión, es posible que las predicciones diverjan y es por esto que un modelo que combine ambas en lugar de efectuarlas por separado será una mejor opción en estos casos.\n",
        "\n",
        "#### **Dudas sobre el tema tratado:**\n",
        "\n",
        "Dado que no me quedó claro en el segundo ejemplo como es que este trabajaba con los modelos de regresión y de clasificación si ambos a la vez o de forma secuencíal, creo que lo mejor es buscar más ejemplos y así teniendo distintas perspectivas poder tener una mejor comprensión de este tema.\n"
      ]
    }
  ]
}